{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZyttynPwtqRPreRXmYk1u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciaPi/Neural-networks-course/blob/main/5Trening_rozdeleny_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tréning neurónovej siete**\n",
        "**Dataset Študenti**\n",
        "\n",
        "https://www.kaggle.com/datasets/rkiattisak/student-performance-in-mathematics"
      ],
      "metadata": {
        "id": "gp5NUsXAthrj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqpta3wzsUrm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Príprava dát**"
      ],
      "metadata": {
        "id": "L_faWUigCDi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls /root/.cache/kagglehub/datasets/rkiattisak/student-performance-in-mathematics/versions/3\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rkiattisak/student-performance-in-mathematics\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "data = pd.read_csv(path+\"/exams.csv\")\n",
        "\n",
        "# zmenime \"lunch\" na 0-1 hodnoty\n",
        "data['lunch'] = data['lunch'].replace({'free/reduced': 1, 'standard': 0})\n",
        "# upravime aj \"gender\" a \"parental level of education\"\n",
        "data['gender'] = data['gender'].replace({'female': 1, 'male': 0})\n",
        "data['parental level of education'] = data['parental level of education'].replace({'some high school': 0,'high school':0,'some college':1,\"associate's degree\":2,\"bachelor's degree\":3,\"master's degree\":4})\n",
        "# zmenime na 0-1 hodnoty stlpec \"test preparation course\"\n",
        "data['test preparation course'] = data['test preparation course'].replace({'completed': 1, 'none': 0})\n",
        "# vymazeme stlpec \"race/ethnicity\"\n",
        "data =data.drop(columns=['race/ethnicity'])\n",
        "\n",
        "# vstupy\n",
        "input_name1 = 'test preparation course'\n",
        "input_name2 = 'reading score'\n",
        "input_name3 = 'writing score'\n",
        "inputs = data[[input_name1,input_name2,input_name3]].copy()\n",
        "\n",
        "# vystup\n",
        "output_name = 'math score'\n",
        "labels = data[output_name].copy()\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "1WiMU1Wlyd5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rozdelenie trénovacích dát**\n",
        "* Train set - ???\n",
        "* Valid set - 10%\n",
        "* Test set -  20%"
      ],
      "metadata": {
        "id": "d5PR8Rf9uoin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_trainval, X_test, y_trainval, y_test = train_test_split(inputs, labels, test_size=???)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=???)"
      ],
      "metadata": {
        "id": "fzi1PUJhtxqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data normalization\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train, y_train = np.array(X_train), np.array(y_train).astype(float)\n",
        "X_val, y_val = np.array(X_val), np.array(y_val).astype(float)\n",
        "X_test, y_test = np.array(X_test), np.array(y_test).astype(float)\n",
        "\n",
        "# upravime data na tenzory\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "X_test = torch.from_numpy(X_test).float()\n",
        "y_train = torch.from_numpy(y_train).float()\n",
        "y_val = torch.from_numpy(y_val).float()\n",
        "y_test = torch.from_numpy(y_test).float()\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape)\n",
        "print(\"Valid:\", X_val.shape, y_val.shape)\n",
        "print(\"Test:\", X_test.shape, y_test.shape)\n",
        "print(\"Example:\", X_train[:5], y_train[:5])"
      ],
      "metadata": {
        "id": "zdSWs2biPeSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Príprava DataLoadera**\n",
        "\n",
        "Samostaný DataLoader pre **train**, **valid** a **test**.\n",
        "\n",
        "**Valid** a **test** DataLoader majú *epoch=1* a *shuffle=False*."
      ],
      "metadata": {
        "id": "0RrixlMHRI4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "# Train set\n",
        "train_tensor = data_utils.TensorDataset(X_train, y_train)\n",
        "train_dataloader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)\n",
        "# Valid set\n",
        "valid_tensor = data_utils.TensorDataset(X_val, y_val)\n",
        "valid_dataloader = data_utils.DataLoader(dataset = valid_tensor, batch_size = 1, shuffle = False)\n",
        "# Test set\n",
        "test_tensor = data_utils.TensorDataset(X_test, y_test)\n",
        "test_dataloader = data_utils.DataLoader(dataset = test_tensor, batch_size = 1, shuffle = False)"
      ],
      "metadata": {
        "id": "l5kxNdSPNvDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Príprava neurónovej siete**"
      ],
      "metadata": {
        "id": "RKanUXTZCQg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prioritne budeme trenovat na GPU karte\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n",
        "\n",
        "# postavime neuronovu siet\n",
        "class StudentiModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(3, 3)  # torch.nn.Linear(in_features, out_features)\n",
        "        self.linear2 = nn.Linear(3, 2)\n",
        "        self.linear3 = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):  # x = vstup\n",
        "        y123 = self.linear1(x)\n",
        "        y45 = self.linear2(y123)\n",
        "        y6 = self.linear3(y45)\n",
        "        return y6\n",
        "\n",
        "# vyrvorime neuronovu siet\n",
        "model = StudentiModel().to(device).eval()\n",
        "model"
      ],
      "metadata": {
        "id": "jMimOz4F9TD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Tréning neurónovej siete**"
      ],
      "metadata": {
        "id": "UsiQF_OsK4Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train() # train() - nastavime model do treningoveho modu (opakom je eval() - evaluacny/netreningovy mod)\n",
        "\n",
        "# optimizer - optimalizuje parametre (vahy, bias) siete\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.00001, momentum=0.9)\n",
        "\n",
        "# Loss funkcia = chyba siete - trening sa ju snazi zlepsit\n",
        "criterion = nn.MSELoss() # MSE=mean squarred error (priemerna stvorcova chyba)\n",
        "\n",
        "# pocet epoch\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "WIqSG1YPR6RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Nájdite rozdiel medzi týmto tréningovým cyklom a cyklom z colab notebooku 3 alebo 4."
      ],
      "metadata": {
        "id": "FXpn2MBbTJrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Start training\")\n",
        "\n",
        "loss_stats_MSE = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}\n",
        "loss_stats_MAE = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}\n",
        "\n",
        "best_model = None\n",
        "best_valid_MSE = 10000\n",
        "\n",
        "for epoch in range(epochs): # pocas jednej epochy prejdeme cely dataset\n",
        "\n",
        "    # inicializujeme pre treningove statistiky\n",
        "    running_loss_mse_train = 0.0\n",
        "    running_mae_train = 0.0\n",
        "\n",
        "    # v cykle prejdeme vsetky data\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # reshape data\n",
        "        inputs = inputs.view(-1,3)\n",
        "        labels = labels.view(-1,1)\n",
        "\n",
        "        # TRAINING\n",
        "        # restartujeme optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # vypocitame vystup siete pre aktualny batch dat\n",
        "        y = model(inputs)\n",
        "\n",
        "        # priemerna absolutna chyba (MAE=mean absolute error)\n",
        "        MAE = abs(labels-y).mean()\n",
        "        running_mae_train += MAE.item()\n",
        "        # chyba siete - trening sa ju snazi zlepsit (MSE=mean squarred error)\n",
        "        loss = criterion(y, labels)\n",
        "\n",
        "        # uprava parametrov siete podla aktualnej chyby (loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss_mse_train += loss.item()\n",
        "\n",
        "        running_loss_mse_val = 0.0\n",
        "        running_mae_val = 0.0\n",
        "        # VALIDATION\n",
        "        with torch.no_grad():     # model sa netrenuje\n",
        "          model.eval()  # evaluacny mod modelu - netrenuje sa\n",
        "          for X_val_batch, y_val_batch in valid_dataloader:\n",
        "              X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
        "\n",
        "              # vypocet vystupov neuronovej siete pre validacne data\n",
        "              y_val_pred = model(X_val_batch)\n",
        "              # vypocet chyby siete pre validacne data\n",
        "              val_loss = criterion(y_val_pred, y_val_batch.unsqueeze(1))\n",
        "              running_loss_mse_val += val_loss.item()\n",
        "              # priemerna absolutna chyba (MAE=mean absolute error)\n",
        "              MAE = abs(y_val_pred-y_val_batch.unsqueeze(1)).mean()\n",
        "              running_mae_val += MAE.item()\n",
        "\n",
        "    # priemerna chyba za celu epochu\n",
        "    MSE_train = running_loss_mse_train/len(train_dataloader)\n",
        "    loss_stats_MSE['train'].append(MSE_train)\n",
        "    MSE_val = running_loss_mse_val/len(valid_dataloader)\n",
        "    loss_stats_MSE['val'].append(MSE_val)\n",
        "    MAE_train = running_mae_train/len(train_dataloader)\n",
        "    loss_stats_MAE['train'].append(MAE_train)\n",
        "    MAE_val = running_mae_val/len(valid_dataloader)\n",
        "    loss_stats_MAE['val'].append(MAE_val)\n",
        "\n",
        "    print('epoch {0}: TRAIN MSE={1:0.2f} MAE={2:0.2f}    VALID MSE={3:0.2f} MAE={4:0.2f}'.format(epoch+1,\n",
        "    MSE_train, MAE_train, MSE_val, MAE_val))\n",
        "\n",
        "    # ulozenie najlepsieho modelu\n",
        "    if (MSE_val <= best_valid_MSE):\n",
        "      best_valid_MSE = MSE_val\n",
        "      best_model = copy.deepcopy(model)\n",
        "\n",
        "print(\"Finished training\")"
      ],
      "metadata": {
        "id": "ieujJyAcK9zw",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Pridali sme **validačnú časť**, čiže už sa počas tréningu neukladá len chyba trénovacích dát, ale aj validačných.\n",
        "* Počas validácie sa model **netrénuje**, je v evaluačnom móde.\n",
        "* Priebežne si ukladáme model s **najlepšou validačnou Loss**. Tento model by mal najlepšie vedieť **generalizovať** a teda ho použijeme aj na testovanie."
      ],
      "metadata": {
        "id": "0JVANhTHaZQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2,2,figsize=(10,4),constrained_layout=True)\n",
        "axes[0,0].plot(loss_stats_MSE['train'], label='Training Loss MSE')\n",
        "axes[0,1].plot(loss_stats_MAE['train'], label='Train MAE')\n",
        "axes[0,0].set_xlabel('Epochs')\n",
        "axes[0,1].set_xlabel('Epochs')\n",
        "axes[0,0].set_title('Training Loss MSE')\n",
        "axes[0,1].set_title('Train MAE')\n",
        "axes[1,0].plot(loss_stats_MSE['val'], label='Valid Loss MSE')\n",
        "axes[1,1].plot(loss_stats_MAE['val'], label='Valid MAE')\n",
        "axes[1,0].set_xlabel('Epochs')\n",
        "axes[1,1].set_xlabel('Epochs')\n",
        "axes[1,0].set_title('Valid Loss MSE')\n",
        "axes[1,1].set_title('Valid MAE')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2VbAhKHqK1Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4. Ohodnotenie siete po tréningu**\n",
        "* Na ohodnotenie modelu použijeme testovacie dáta."
      ],
      "metadata": {
        "id": "7bHGJatA8z48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ohodnotenie testovacích dát**"
      ],
      "metadata": {
        "id": "vBOHUS39ez3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vystup celeho datasetu\n",
        "y_pred_list = []\n",
        "with torch.no_grad():\n",
        "    # nastavime model do evaluacneho (netreningoveho modu)\n",
        "    best_model.eval()\n",
        "    for X_batch, _ in test_dataloader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_test_pred = best_model(X_batch)\n",
        "        y_pred_list.append(y_test_pred.cpu().numpy())\n",
        "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
        "\n",
        "# priemerna absolutna chyba (MAE=mean absolute error)\n",
        "MAE = abs(y_pred_list-y_test.numpy()).mean().item()\n",
        "\n",
        "# priemerna stvorcova chyba (MSE=mean squarred error)\n",
        "MSE = ((y_pred_list-y_test.numpy())**2).mean().item()\n",
        "\n",
        "print(\"MAE:\",MAE)\n",
        "print(\"MSE:\",MSE)"
      ],
      "metadata": {
        "id": "0Qp0fyH-bN48"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}